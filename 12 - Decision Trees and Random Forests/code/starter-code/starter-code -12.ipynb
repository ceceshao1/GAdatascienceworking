{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Evergreeness of Content with Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "      <td>A sign stands outside the International Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
       "      <td>8471</td>\n",
       "      <td>{\"title\":\"The Fully Electronic Futuristic Star...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "      <td>The Fully Electronic Futuristic Starting Gun T...</td>\n",
       "      <td>And that can be carried on a plane without the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "1  http://www.popsci.com/technology/article/2012-...   8471   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "1  {\"title\":\"The Fully Electronic Futuristic Star...       recreation   \n",
       "\n",
       "  alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0               0.789131     2.055556           0.676471           0.205882   \n",
       "1               0.574147     3.677966           0.508021           0.288770   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  \\\n",
       "0           0.047059           0.023529   \n",
       "1           0.213904           0.144385   \n",
       "\n",
       "                         ...                          linkwordscore  \\\n",
       "0                        ...                                     24   \n",
       "1                        ...                                     40   \n",
       "\n",
       "   news_front_page  non_markup_alphanum_characters  numberOfLinks  \\\n",
       "0                0                            5424            170   \n",
       "1                0                            4973            187   \n",
       "\n",
       "   numwords_in_url  parametrizedLinkRatio  spelling_errors_ratio label  \\\n",
       "0                8               0.152941               0.079130     0   \n",
       "1                9               0.181818               0.125448     1   \n",
       "\n",
       "                                               title  \\\n",
       "0  IBM Sees Holographic Calls Air Breathing Batte...   \n",
       "1  The Fully Electronic Futuristic Starting Gun T...   \n",
       "\n",
       "                                                body  \n",
       "0  A sign stands outside the International Busine...  \n",
       "1  And that can be carried on a plane without the...  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the stumbleupon.tsv data - notice the use of the \"sep\" parameter here.\n",
    "# This is tab-separated file and not a comma-separated file, so the \"sep\"\n",
    "# parameter is set to \"\\t\" to denote tab.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "data = pd.read_csv(\"../../assets/dataset/stumbleupon.tsv\", sep='\\t')\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7395, 29)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of your new dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body     57\n",
       "title    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()[data.isnull().sum() != 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Address missing values by dropping rows with missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spot check your work\n",
    "data.isnull().sum()[data.isnull().sum() != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting \"Greenness\" Of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from [stumbleupon](https://www.stumbleupon.com/), a web page recommender. A description of the columns is below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "title|string|Title of the article\n",
    "body|string|Body text of article\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonlinkratio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonlinkratio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonlinkratio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonlinkratio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are \"evergreen\" sites?\n",
    "\n",
    "> #### Evergreen sites are those that are always relevant.  As opposed to breaking news or current events, evergreen websites are relevant no matter the time or season. \n",
    "\n",
    "> #### A sample of URLs below where label = 1 are \"evergreen\" websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[['url', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercises to Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Exercise: 1. In a group: Brainstorm 3 - 5 features you could develop that would be useful for predicting evergreen websites.\n",
    " ###  Exercise: 2. After looking at the dataset, can you model or quantify any of the characteristics you wanted?\n",
    "- If you believe high-image content websites are likely to be evergreen, how can you build a feature that represents that?\n",
    "- If you believe weather content is likely NOT to be evergreen, how might you build a feature that represents that?\n",
    "\n",
    "### Split up and develop 1-3 of those features independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: 3. Does being a news site affect evergreeness? \n",
    "Compute and/or plot the percentage of news related evergreen sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "# data.is_news.value_counts()\n",
    "\n",
    "# is_news = True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "\n",
    "# Option 1: Find out P ( evergreen | is_news = 1) vs P ( evergreen | is_news = ?)\n",
    "\n",
    "data.groupby(['is_news'])[['label']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A visualized version of the output above\n",
    "sns.factorplot(x='is_news', y='label', kind='bar', data = data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: 4. Does category in general affect evergreeness? \n",
    "\n",
    "Compute and/or plot the rate of evergreen sites for all Alchemy categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: 5. How many articles are there per alchemy category?\n",
    "Compute and/or plot the count of evergreen sites for all Alchemy categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Let's try extracting some of the text content.\n",
    "> ### Exercise: 6. Create a feature for the title containing 'recipe'. \n",
    "Is the % of evegreen websites higher or lower on pages that have recipe in the the title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 1: Create a function to check for this\n",
    "\n",
    "# Try/Except: If an error is encountered, the try block code execution\n",
    "# is stopped and transferred down to the except block.\n",
    "def has_recipe(text_in):\n",
    "    try:\n",
    "        if 'recipe' in str(text_in).lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except: \n",
    "        return 0\n",
    "\n",
    "# Map our newly created function to the title column in our dataset\n",
    "# and assign the output of 1's and 0's to a new data column \"recipe\"\n",
    "data['recipe'] = data['title'].map(has_recipe)\n",
    "\n",
    "# Option 2: lambda functions\n",
    "\n",
    "#data['recipe'] = data['title'].map(lambda t: 1 if 'recipe' in str(t).lower() else 0)\n",
    "\n",
    "# Option 3: string functions\n",
    "\n",
    "# Similar to above but the output will be bools \n",
    "# (true/false) instead of 1's and 0's.\n",
    "\n",
    "#data['recipe'] = data['title'].str.contains('recipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In this newly created column, check to see how\n",
    "# many pages had recipe in the the title.\n",
    "data.recipe.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  Let's Explore Some Decision Trees:\n",
    "\n",
    "`In essence, decision trees are just a sequence of \"if this, than that\" conditions.`\n",
    "\n",
    "`1. They are non-parametric (no assumptions about the distribution(s) of your data).`<br>\n",
    "`2. No coefficients`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo: Build a decision tree model to predict the \"evergreeness\" of a given website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the DecisionTree Classifier from scikit's tree module\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate your dtc object as assign it to the variable name \"model\"\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Select your features\n",
    "X = data[['image_ratio', 'html_ratio', 'recipe']]\n",
    "\n",
    "# Set your target variable\n",
    "y = data['label']\n",
    "    \n",
    "    \n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Helper function to visualize Decision Trees (creates a file tree.png)\n",
    "from sklearn.tree import export_graphviz\n",
    "from os import system \n",
    "def build_tree_image(model):\n",
    "    dotfile = open(\"tree.dot\", 'w')\n",
    "    export_graphviz(model, out_file = dotfile, feature_names = X.columns)\n",
    "    dotfile.close()\n",
    "    system(\"dot -Tpng tree.dot -o tree.png\")\n",
    "    \n",
    "build_tree_image(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we're going to take a sample of our data and attempt to visualize it right inside the notebook.\n",
    "\n",
    "`The full X and y would not output in Jupyter notebook. Attempts were a real kernel killer.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The way a decision tree works is that it attempts to find the decision that will best segregate the classes.\n",
    "\n",
    "`When entropy is 1, the classes are balanced and when entropy is 0 everything is the same class.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graph_model = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=42)\n",
    "graph_model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "# Setting class_weight to 'balanced' will replicate the \n",
    "# minority class until the two classes have equal representation\n",
    "\n",
    "# When proportion=True, the output is the fraction of records \n",
    "# for each class that have reached that node.\n",
    "\n",
    "graph_X = X[:200]\n",
    "graph_y = y[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(graph_X.shape)\n",
    "print(graph_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_model.fit(graph_X, graph_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(graph_model, out_file=None, feature_names=X.columns,\n",
    "                                filled=True, rounded=True, special_characters=True) \n",
    "graph = pydotplus.graphviz.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`If we don't put any limits on the decision tree classifier, what do see? It just continues splitting until entropy is zero (all examples in that node are in the same class).` \n",
    "\n",
    "`Q: Why might that be a problem?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A. Overfitting. A common problem with decision trees.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo: Evaluate the decision tree we just created using cross-validation; use AUC as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# model is the estimator or the object to used to fit the data.\n",
    "# X is your features, y is your target. You then select a scoring method -\n",
    "# here we choose area under the curve (auc) as the evaluation metric. \n",
    "# cv: the number of folds (default is 3)\n",
    "scores = cross_val_score(model, graph_X, graph_y, scoring='roc_auc', cv=5)\n",
    "print('CV AUC {}, \\nAverage AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`How we can address overfitting concerns?` \n",
    "\n",
    "###  Adjusting Decision Trees to Avoid Overfitting:\n",
    "\n",
    "DecisionTreeClassifier(): This is the classifier function for DecisionTree. It is the main function for implementing the algorithms. Some important parameters are:\n",
    "\n",
    "- **criterion**: It defines the function to measure the quality of a split. Sklearn supports “gini” criteria for Gini Index & “entropy” for Information Gain. By default, it takes “gini” value.\n",
    "- **splitter**: It defines the strategy to choose the split at each node. Supports “best” value to choose the best split & “random” to choose the best random split. By default, it takes “best” value.\n",
    "- **max_features**: It defines the no. of features to consider when looking for the best split. We can input integer, float, string & None value.\n",
    "If an integer is inputted then it considers that value as max features at each split.\n",
    "If float value is taken then it shows the percentage of features at each split.\n",
    "If “auto” or “sqrt” is taken then max_features=sqrt(n_features).\n",
    "If “log2” is taken then max_features= log2(n_features).\n",
    "If None, then max_features=n_features. By default, it takes “None” value.\n",
    "- **max_depth**: The max_depth parameter denotes maximum depth of the tree. It can take any integer value or None. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. By default, it takes “None” value.\n",
    "- **min_samples_split**: This tells above the minimum no. of samples reqd. to split an internal node. If an integer value is taken then consider min_samples_split as the minimum no. If float, then it shows percentage. By default, it takes “2” value.\n",
    "- **min_samples_leaf**: The minimum number of samples required to be at a leaf node. If an integer value is taken then consider min_samples_leaf as the minimum no. If float, then it shows percentage. By default, it takes “1” value.\n",
    "- **max_leaf_nodes**: It defines the maximum number of possible leaf nodes. If None then it takes an unlimited number of leaf nodes. By default, it takes “None” value.\n",
    "- **min_impurity_split**: It defines the threshold for early stopping tree growth. A node will split if its impurity is above the threshold otherwise it is a leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo: Control for overfitting in the decision model by adjusting the maximum number of questions (max_depth) or the minimum number of records in each final node (min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiating a Decision Tree Classifier with explicit setting of max_depth=2 \n",
    "# (instead of the default which is max_depth=None) and explicit setting of \n",
    "# min_samples_leaf=5 (instead of the default which is min_samples_leaf=2)\n",
    "model = DecisionTreeClassifier(max_depth=2, min_samples_leaf=5)\n",
    "\n",
    "# Fit your model\n",
    "model.fit(X, y)\n",
    "build_tree_image(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo: Build a random forest model to predict the evergreeness of a website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier from scikit's ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instanitate your Random Forest Classifier model object with n_estimators or\n",
    "# the number of trees in the forest set to 20 (default is 10)\n",
    "model = RandomForestClassifier(n_estimators = 20)\n",
    "\n",
    "# Fit your model on the features (X) and the target (y)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo: Extracting importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set features variable with the names of the features in X\n",
    "features = X.columns\n",
    "print(\"Feature columns:\", features)\n",
    "\n",
    "# Set feature_importances variable using the attribute \"feature_importances_\".\n",
    "# The higher the score, the more important the feature in that particular combination.\n",
    "# If you changed the features in X it would impact the scores.\n",
    "# Similar to coefficients in that respect.\n",
    "feature_importances = model.feature_importances_\n",
    "print(\"Feature Importance scores:\", feature_importances)\n",
    "\n",
    "# Create a dataframe of the features and their respective importance scores\n",
    "features_df = pd.DataFrame({'Features': features, 'Importance Score': feature_importances})\n",
    "\n",
    "# Sort the values by \"Importance Score\" with ascending in false to ensure\n",
    "# the score appear from highest to lowest in the new dataframe\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seaborn's factorplot draws a categorical plot onto a FacetGrid WITH COLORS!\n",
    "sns.factorplot(x='Features', y='Importance Score', kind='bar', data = features_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo: Evaluate the Random Forest model using cross-validation; increase the number of estimators and view how that improves predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "# cross_val_score(estimator, features, target, chosen scoring method) assigned to the variable \"scores.\"\n",
    "# scores will be a numpy array\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc')\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))\n",
    "\n",
    "# A for loop for running a Random Forest Classifier with n-estimators (or number of trees in your forest).\n",
    "# The is 1 to 100 in steps of 10 - range(start, end, step)\n",
    "for n_trees in range(1, 100, 10):\n",
    "    model = RandomForestClassifier(n_estimators = n_trees)\n",
    "    scores = cross_val_score(model, X, y, scoring='roc_auc')\n",
    "    print('n trees: {}, CV AUC {}, Average AUC {}'.format(n_trees, scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Independent Practice: Evaluate Random Forest Using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Continue adding input variables to the model that you think may be relevant\n",
    "2. For each feature:\n",
    "  - Evaluate the model for improved predictive performance using cross-validation\n",
    "  - Evaluate the _importance_ of the features and create a quick plot to visually express the _importance_ of those features\n",
    "3. **Bonus**: Just like the `recipe` feature, add in similar **text** features and evaluate the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build a model with more relevant features\n",
    "\n",
    "- Instantiate your model object\n",
    "- Define your features (X) and your target (y)\n",
    "- Fit your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Evaluate predictive performance for the given feature set\n",
    "\n",
    "`Here's an example from some ship people won't stop talking about:`\n",
    "\n",
    "`scores = cross_validation.cross_val_score(model, titanic[features] (or X), titanic[target] (or y), cv=10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate with cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Evaluating feature importances "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`If unsure how to proceed, review the demo earlier in the notebook regarding extracting the importance of features and the subsequent use of seaborn to visually display those feature importances.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get columns and their importance scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seaborn's factorplot STILL draws a categorical plot onto a FacetGrid WITH COLORS!\n",
    "# What a time to be alive!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BONUS!!! Add in text features (strings, objects) and do it all over again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`How many text columns options do you have?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What are your text column options?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data.loc[:, data.dtypes == object].columns\n",
    "data.select_dtypes(exclude=[np.number]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create a new model with a text features or many text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here's an example:\n",
    "\n",
    "#Check for keywords in the title\n",
    "data['PhotoInTitle'] = data['title'].fillna('').str.lower().str.contains('photo').astype(int)\n",
    "\n",
    "# New X with an additional feature\n",
    "\n",
    "\n",
    "# Still the same target variable \"label\"\n",
    "\n",
    "\n",
    "# Fit a model on your data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your new text-inclusive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cross_val_score(estimator, features, target, chosen scoring method)\n",
    "# assigned to the variable \"scores\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and visually express the feature importances of your new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get columns and their importance scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seaborn's factorplot STILL draws a categorical plot onto a FacetGrid WITH COLORS!\n",
    "# What a time to be alive!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUT WAIT, THERE'S MORE BONUSES! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://imgflip.com/i/253hro\"><img src=\"https://i.imgflip.com/253hro.jpg\" title=\"made at imgflip.com\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also tune your Random Forest Classifier hyperparameters using GridsearchCV!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Here's an example of gridsearchCV parameter dictionary from good old kNN:`\n",
    "\n",
    "`knn_dict = {\n",
    "    'n_neighbors': [10, 12, 14, 16],\n",
    "    'p': [1, 2],\n",
    "    'weights': ['uniform', 'distance']}`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find parameter options here: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import GridSearchCV from sklearn's model selection library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print('Processing GridSearch. Please hold for the next available set of outputs.\\n')\n",
    "# Review the plethora of hyperparameter options for Random Forest Classifiers, and\n",
    "# then fill in some options for each hyperparameter you selected in a similar format\n",
    "# as the kNN example.\n",
    "gd_parameters = {   }\n",
    "\n",
    "# Instantiate a new model object\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "gd_model = GridSearchCV(rf, gd_parameters, n_jobs = -1, cv=10)\n",
    "\n",
    "# Fit your model\n",
    "\n",
    "\n",
    "# Find your best combination of parameters and \n",
    "# the score associated with that combinations\n",
    "print(gd_model.best_params_)\n",
    "#print(gd_model.best_estimator_)\n",
    "print(gd_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification not for you? Fancy yourself a regression aficionado? \n",
    "### That's just fine! Scikit's got your back.\n",
    "\n",
    "`The Ames Housing Training and Test .csvs are available for you to lexplore the Regressor versions of Decision Trees\n",
    "and Random Forests.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "ames_train = pd.read_csv(\"../../assets/dataset/Ames_train.csv\")\n",
    "ames_test = pd.read_csv(\"../../assets/dataset/Ames_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
