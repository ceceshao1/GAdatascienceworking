{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Neural Networks with Keras\n",
    "\n",
    "_Authors: Justin Pounders (ATL) and Riley Dalles (ATX)_\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "- Describe the basic `keras` workflow.\n",
    "- Train regression and classification neural networks using `keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "`keras` is a convenience layer over `tensorflow`.  Let's look at a typical workflow:\n",
    "\n",
    "1. Load the data.\n",
    "2. Data cleaning/munging, feature engineering \n",
    "3. Make test/train splits. \n",
    "4. Standardize the data.\n",
    "5. Build a computational graph for the neural network.\n",
    "6. Train the network using gradient descent a.k.a. back propogation.\n",
    "7. Evaluate performance and iterate.\n",
    "\n",
    "The \"big\" steps are 5 and 6.\n",
    "\n",
    "- 5 Build the network by creating linked `dense` layers.\n",
    "- 6 Iterate over epochs (and possibly batches), explicitly calling on the session to execute a \"training op\"\n",
    "\n",
    "In `keras` these to steps are simplified.\n",
    "\n",
    "- 5 Add layers to a \"model\".\n",
    "- 6 Compile and fit the model. (as little as 2 lines of code!)\n",
    "\n",
    "---\n",
    "\n",
    "**Regardless of the tool that you are using**, keep in mind the following concepts:\n",
    "\n",
    "- What will your network topology (number of hidden layers and units per layer) be?\n",
    "- What activation function will you use for the hidden layers?\n",
    "- Based on your model, how many units will be in your input and output layers?\n",
    "- Based on your model, what will the activation function on your output layer be?\n",
    "- What will your loss function be?\n",
    "- What optimizer will you use for the gradient descent/backpropogation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of Keras Model:\n",
    "- from keras. models import sequential (model type)\n",
    "- from keras.layers import dense dropout\n",
    "- from keras.layers import adam --> \n",
    "\n",
    "- from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes dataset\n",
      "================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "Data Set Characteristics:\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attributes:\n",
      "    :Age:\n",
      "    :Sex:\n",
      "    :Body mass index:\n",
      "    :Average blood pressure:\n",
      "    :S1:\n",
      "    :S2:\n",
      "    :S3:\n",
      "    :S4:\n",
      "    :S5:\n",
      "    :S6:\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_diabetes()\n",
    "print (data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 38.,  80.,  68.,  62.,  50.,  41.,  38.,  42.,  17.,   6.]),\n",
       " array([  25. ,   57.1,   89.2,  121.3,  153.4,  185.5,  217.6,  249.7,\n",
       "         281.8,  313.9,  346. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0CWpERa6JDXCQpekRljoktSI/wdESX77rKwf+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0f44ae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data matrix (i.e., input features) are stored in `data.data`; the target values are stored in `data.target`.\n",
    "\n",
    "To prepare your data...\n",
    "\n",
    "1. Split your data into train and test sets.\n",
    "2. Standardize your data.\n",
    "\n",
    "> Note that the description indicate that these data have already been scaled.  Let's go through the motions and scale explicitly here, since you typically will _not_ have someone else scaling your data for you.  Hey, **your're** the data scientist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((331, 10), (111, 10), (331,), (111,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prep the data\n",
    "X = data.data # (see note above re: data matrix)\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#check shap and make sure the numbers match up / form two pairs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data ready to go, let's build our first model.\n",
    "\n",
    "> Review the key characteristics of a regression model.  How many, output units will we have?  What will the activation function on the output unit be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_units = X_train.shape[1] # number of features = second number of the tuple (331, 10) X_train.shape[1]\n",
    "hidden_units = input_units #start with a hidden layer that has the same number of units as input units (features)\n",
    "\n",
    "model.add(Dense(hidden_units, input_dim=input_units, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the \n",
    "# element-wise activation function passed as the activation argument, kernel is a weights matrix created \n",
    "# by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam #importing module \n",
    "\n",
    "#need to create object to instantiate something you imported \n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 331 samples, validate on 111 samples\n",
      "Epoch 1/10\n",
      "331/331 [==============================] - 0s 143us/step - loss: 3828.2315 - val_loss: 3225.6112\n",
      "Epoch 2/10\n",
      "331/331 [==============================] - 0s 140us/step - loss: 3493.0757 - val_loss: 3087.2092\n",
      "Epoch 3/10\n",
      "331/331 [==============================] - 0s 129us/step - loss: 3241.1237 - val_loss: 2978.0168\n",
      "Epoch 4/10\n",
      "331/331 [==============================] - 0s 125us/step - loss: 3091.9618 - val_loss: 2864.3668\n",
      "Epoch 5/10\n",
      "331/331 [==============================] - 0s 127us/step - loss: 2981.5484 - val_loss: 2836.1874\n",
      "Epoch 6/10\n",
      "331/331 [==============================] - 0s 135us/step - loss: 2898.8817 - val_loss: 2808.1089\n",
      "Epoch 7/10\n",
      "331/331 [==============================] - 0s 137us/step - loss: 2824.4273 - val_loss: 2782.6139\n",
      "Epoch 8/10\n",
      "331/331 [==============================] - 0s 134us/step - loss: 2788.6569 - val_loss: 2825.3050\n",
      "Epoch 9/10\n",
      "331/331 [==============================] - 0s 143us/step - loss: 2770.4496 - val_loss: 2780.7128\n",
      "Epoch 10/10\n",
      "331/331 [==============================] - 0s 133us/step - loss: 2780.9708 - val_loss: 2823.3514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0f44acd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), #needs validation now in order to backprogate\n",
    "          epochs=10, batch_size=None)\n",
    "\n",
    "\n",
    "# score later with test data (cross validation)\n",
    "#results in the different Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = load_breast_cancer()\n",
    "print (data2.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
