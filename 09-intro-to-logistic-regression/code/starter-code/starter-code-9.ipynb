{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Practice: Logit Function and Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceceliashao/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# Statsmodels logistic regression is sm.Logit\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the PDF/slides\n",
    "Given the odds below for some football games, use the logit function and the sigmoid function to solve for the probability that the “better” team would win. \n",
    "\n",
    "- a. Stanford : Iowa, 5:1\n",
    "- b. Alabama : Michigan State, 20:1\n",
    "- c. Clemson : Oklahoma, 1.1:1\n",
    "- d. Houston : Florida State, 1.8:1\n",
    "- e. Ohio State : Notre Dame, 1.6:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odds_set = [5./1, 20./1, 1.1/1, 1.8/1, 1.6/1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_func(odds): \n",
    "# uses a float (odds) and returns back the log odds (logit) \n",
    "    log_odds = np.log(odds)\n",
    "    return log_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_func(logit): \n",
    "# uses a float (logit) and returns back the probability \n",
    "    return 1. / (1 + np.exp(-logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833333333333\n",
      "0.952380952381\n",
      "0.52380952381\n",
      "0.642857142857\n",
      "0.615384615385\n"
     ]
    }
   ],
   "source": [
    "for odds in odds_set:\n",
    "    print(sigmoid_func(logit_func(odds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../assets/dataset/collegeadmissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify the prestige categorical variable\n",
    "df = df.join(pd.get_dummies(df['rank'], prefix=\"rank\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank  rank_1  rank_2  rank_3  rank_4\n",
       "0      0  380  3.61     3       0       0       1       0\n",
       "1      1  660  3.67     3       0       0       1       0\n",
       "2      1  800  4.00     1       1       0       0       0\n",
       "3      1  640  3.19     4       0       0       0       1\n",
       "4      0  520  2.93     4       0       0       0       1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   400</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   394</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 13 Feb 2018</td> <th>  Pseudo R-squ.:     </th>  <td>0.08292</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:31:24</td>     <th>  Log-Likelihood:    </th> <td> -229.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -249.99</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>7.578e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>   -5.5414</td> <td>    1.138</td> <td>   -4.869</td> <td> 0.000</td> <td>   -7.772</td> <td>   -3.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>    <td>    0.0023</td> <td>    0.001</td> <td>    2.070</td> <td> 0.038</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>    <td>    0.8040</td> <td>    0.332</td> <td>    2.423</td> <td> 0.015</td> <td>    0.154</td> <td>    1.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_1</th> <td>    1.5515</td> <td>    0.418</td> <td>    3.713</td> <td> 0.000</td> <td>    0.733</td> <td>    2.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_2</th> <td>    0.8760</td> <td>    0.367</td> <td>    2.389</td> <td> 0.017</td> <td>    0.157</td> <td>    1.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_3</th> <td>    0.2113</td> <td>    0.393</td> <td>    0.538</td> <td> 0.591</td> <td>   -0.559</td> <td>    0.981</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  400\n",
       "Model:                          Logit   Df Residuals:                      394\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Tue, 13 Feb 2018   Pseudo R-squ.:                 0.08292\n",
       "Time:                        19:31:24   Log-Likelihood:                -229.26\n",
       "converged:                       True   LL-Null:                       -249.99\n",
       "                                        LLR p-value:                 7.578e-08\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -5.5414      1.138     -4.869      0.000      -7.772      -3.311\n",
       "gre            0.0023      0.001      2.070      0.038       0.000       0.004\n",
       "gpa            0.8040      0.332      2.423      0.015       0.154       1.454\n",
       "rank_1         1.5515      0.418      3.713      0.000       0.733       2.370\n",
       "rank_2         0.8760      0.367      2.389      0.017       0.157       1.595\n",
       "rank_3         0.2113      0.393      0.538      0.591      -0.559       0.981\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set our features/predictors to X\n",
    "# drop rank_4\n",
    "X = df[['gre', 'gpa', 'rank_1', 'rank_2', 'rank_3',]]\n",
    "\n",
    "# Add the intercept as recommended by statsmodels\n",
    "# (An intercept is not included by default and should be added by the user.) \n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Set our target variable to y\n",
    "y = df['admit']\n",
    "\n",
    "# Call your Logit function and fit the model\n",
    "# Note: Order of inputs is important here:\n",
    "# First y (dependent variable, target variable, endog) then X (features, exog)\n",
    "lr = sm.Logit(y, X).fit()\n",
    "\n",
    "# Output your summary of results from your model\n",
    "lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    -5.541443\n",
       "gre       0.002264\n",
       "gpa       0.804038\n",
       "rank_1    1.551464\n",
       "rank_2    0.876021\n",
       "rank_3    0.211260\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use \"lr.params\" to output just your model coefficients\n",
    "lr.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const     0.003921\n",
       "gre       1.002267\n",
       "gpa       2.234545\n",
       "rank_1    4.718371\n",
       "rank_2    2.401325\n",
       "rank_3    1.235233\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can convert those coefficients into odds ratios using np.exp()\n",
    "np.exp(lr.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some code to walk through confusion matrices. It'll be useful for working through the Titanic problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the ROC curve is based on various thresholds: it shows with a false positive rate (x-axis) ~0, it also expects a true positive rate (y-axis) ~0 (the same, ish, for the top right hand of the figure).\n",
    "\n",
    "The second chart, which does not play with thesholds, shows the one true TPR and FPR point, joined to 0,0 and 1,1.\n",
    "\n",
    "The first chart will be more effective as you compare models and determine where the decision line should exist for the data. The second simplifies the first in case this idea of thresholds is confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70999999999999996"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = lr.predict(X)\n",
    "threshold = 0.5\n",
    "predicted_classes = (predicted > threshold).astype(int)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113cbab50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(roc_curve(df[['admit']], predicted)[0], roc_curve(df[['admit']], predicted)[1])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('ROC curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the `roc_auc_score` function to calculate the area under these curves (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58331170142193767"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df['admit'], predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Goals **\n",
    "\n",
    "1. Spend a few minutes determining which data would be most important to use in the prediction problem. You may need to create new features based on the data available. Consider using a feature selection aide in sklearn. But a worst case scenario; identify one or two strong features that would be useful to include in the model.\n",
    "2. Spend 1-2 minutes considering which _metric_ makes the most sense to optimize. Accuracy? FPR or TPR? AUC? Given the business problem (understanding survival rate aboard the Titanic), why should you use this metric?\n",
    "3. Build a tuned Logistic model. Be prepared to explain your design (including regularization), metric, and feature set in predicting survival using the tools necessary (such as a fit chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
